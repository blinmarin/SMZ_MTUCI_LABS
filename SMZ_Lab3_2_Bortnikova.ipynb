{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyJ4qqH0h4__",
        "outputId": "b6e8dbb8-9cb5-4730-c7ca-e0b1f7cc2fa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting myConv.py\n"
          ]
        }
      ],
      "source": [
        "%%file myConv.py\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "def myTranspConv2d(in_channels, out_channels, kernel_size, transp_stride=1, padding=0, dilation=1, bias=True, padding_mode='zeros'):\n",
        "  def Svertca(matrix):\n",
        "\n",
        "    #всегда 1 шаг\n",
        "    stride = 1\n",
        "\n",
        "    #добавление отступов и padding в входной матрице\n",
        "    pad = kernel_size - 1\n",
        "    result_matrix = []\n",
        "    for matr in matrix:\n",
        "      zero_tensor = np.zeros((((matr.shape[0]-1)*(transp_stride)+1), ((matr.shape[1]-1)*(transp_stride)+1)))\n",
        "      for a in range (0, zero_tensor.shape[0], transp_stride):\n",
        "        for b in range (0, zero_tensor.shape[1], transp_stride):\n",
        "          zero_tensor[a][b] = matr[a//(transp_stride)][b//(transp_stride)]\n",
        "\n",
        "      pad_matr = np.pad(zero_tensor, pad_width=pad, mode='constant')\n",
        "      result_matrix.append(pad_matr)\n",
        "    matrix = torch.tensor(result_matrix)\n",
        "\n",
        "    #генерация bias\n",
        "    if bias == True:\n",
        "      bias_val = torch.rand(out_channels)\n",
        "    else:\n",
        "      bias_val = torch.zeros(out_channels)\n",
        "\n",
        "    #padding_mode\n",
        "    if (padding_mode == 'zeros'):\n",
        "      pad = torch.nn.ZeroPad2d(padding)\n",
        "      matrix = pad(matrix)\n",
        "    if (padding_mode == 'reflect'):\n",
        "      pad = torch.nn.ReflectionPad2d(padding)\n",
        "      matrix = pad(matrix)\n",
        "    if (padding_mode == 'replicate'):\n",
        "      pad = torch.nn.ReplicationPad2d(padding)\n",
        "      matrix = pad(matrix)\n",
        "    if (padding_mode == 'circular'):\n",
        "      pad = torch.nn.CircularPad2d(padding)\n",
        "      matrix = pad(matrix)\n",
        "\n",
        "    #генерация ядра\n",
        "    filter = np.array(torch.rand(out_channels, in_channels, kernel_size, kernel_size))\n",
        "\n",
        "    #инвертирование ядра для ConvTranspose2d\n",
        "    filter_for_transpose = []\n",
        "    for j in range(out_channels):\n",
        "      filter_in = []\n",
        "      for i in range(in_channels):\n",
        "        filter_in.append(np.flip(np.array(filter[j][i])))\n",
        "      filter_for_transpose.append(filter_in)\n",
        "\n",
        "    filter_for_transpose = torch.tensor(filter_for_transpose)\n",
        "    filter_for_transpose = filter_for_transpose.reshape(in_channels, out_channels, kernel_size, kernel_size)\n",
        "\n",
        "\n",
        "\n",
        "    spisok = []\n",
        "    for l in range(out_channels):\n",
        "      feature_map = np.array([]) #генерация пустой feature-map\n",
        "      for i in range (0, matrix.shape[1]-((filter.shape[2]-1)*dilation+1)+1, stride): #(filter.size - 1)*dilation + 1 при delation\n",
        "        for j in range (0, matrix.shape[2]-((filter.shape[3]-1)*dilation+1)+1, stride):\n",
        "          summa = 0\n",
        "          for c in range (in_channels):\n",
        "            val = matrix[c][i:i+(filter.shape[2]-1)*dilation+1:dilation, j:j+(filter.shape[3]-1)*dilation+1:dilation]\n",
        "            mini_sum = (val*filter[l][c]).sum()\n",
        "            summa = summa + mini_sum\n",
        "          feature_map = np.append(feature_map, float(summa + bias_val[l])) #bias\n",
        "      spisok.append(feature_map.reshape((matrix.shape[1]-((filter.shape[2]-1)*dilation+1))//stride+1, (matrix.shape[2]-((filter.shape[3]-1)*dilation+1))//stride+1))\n",
        "\n",
        "\n",
        "    return np.array(spisok), torch.tensor(np.array(filter_for_transpose)), torch.tensor(np.array(bias_val))\n",
        "\n",
        "  return Svertca"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file conftest.py\n",
        "\n",
        "from pytest import fixture\n",
        "import requests\n",
        "\n",
        "@fixture\n",
        "def session():\n",
        "  s = requests.Session()\n",
        "  s.headers.update({\"User-Agent\": \"pytest requests\"})\n",
        "  s.verify = True\n",
        "  yield s\n",
        "  s.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl6rTgZVu8nC",
        "outputId": "5541b879-3bd2-4bab-e5b3-55d6165dacb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting conftest.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file test_http.py\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/myConv.py\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "from myConv import myTranspConv2d\n",
        "\n",
        "tensor1 = torch.rand(3, 5, 6)\n",
        "tensor2 = torch.rand(1, 28, 28)\n",
        "tensor3 = torch.rand(7, 10, 10)\n",
        "\n",
        "\n",
        "def test_1(session):\n",
        "  myFunction = myTranspConv2d(in_channels=3, out_channels=1, kernel_size=3, transp_stride=2, bias=True,)\n",
        "  result, kernel, bias_val = myFunction(tensor1)\n",
        "  torchFunction = torch.nn.ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=3, stride=2, bias=True,)\n",
        "  torchFunction.weight.data = kernel\n",
        "  torchFunction.bias.data = bias_val\n",
        "  myResult = str(np.round(result, 2))\n",
        "  torchResult = str(np.round(np.array(torchFunction(tensor1).data), 2))\n",
        "  assert torchResult == myResult\n",
        "\n",
        "\n",
        "def test_2(session):\n",
        "  myFunction2 = myTranspConv2d(in_channels=1, out_channels=2, kernel_size=4, transp_stride=3, bias=True)\n",
        "  result2, kernel2, bias_val2 = myFunction2(tensor2)\n",
        "  torchFunction2 = torch.nn.ConvTranspose2d(in_channels=1, out_channels=2, kernel_size=4, stride=3, bias=True)\n",
        "  torchFunction2.weight.data = kernel2\n",
        "  torchFunction2.bias.data = bias_val2\n",
        "  myResult2 = str(np.round(result2, 2))\n",
        "  torchResult2 = str(np.round(np.array(torchFunction2(tensor2).data), 2))\n",
        "  assert torchResult2 == myResult2\n",
        "\n",
        "\n",
        "def test_3(session):\n",
        "  myFunction3 = myTranspConv2d(in_channels=7, out_channels=1, kernel_size=3, transp_stride=5, bias=True)\n",
        "  result3, kernel3, bias_val3 = myFunction3(tensor3)\n",
        "  torchFunction3 = torch.nn.ConvTranspose2d(in_channels=7, out_channels=1, kernel_size=3, stride=5, bias=True)\n",
        "  torchFunction3.weight.data = kernel3\n",
        "  torchFunction3.bias.data = bias_val3\n",
        "  myResult3 = str(np.round(result3, 2))\n",
        "  torchResult3 = str(np.round(np.array(torchFunction3(tensor3).data), 2))\n",
        "  assert torchResult3 == myResult3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYLRnG6Tu9wO",
        "outputId": "41172299-34ba-4f12-8159-c799555abfd2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting test_http.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol2kjzlIwcZc",
        "outputId": "e8d97980-f4f6-4e9d-81de-da7ab914de70"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-7.4.3, pluggy-1.3.0\n",
            "rootdir: /content\n",
            "plugins: anyio-3.7.1\n",
            "collected 3 items                                                                                  \u001b[0m\n",
            "\n",
            "test_http.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                                                             [100%]\u001b[0m\n",
            "\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "test_http.py::test_1\n",
            "  /content/myConv.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "    matrix = torch.tensor(result_matrix)\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[33m=================================== \u001b[32m3 passed\u001b[0m, \u001b[33m\u001b[1m1 warning\u001b[0m\u001b[33m in 4.85s\u001b[0m\u001b[33m ===================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/myConv.py\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "from myConv import myTranspConv2d\n",
        "\n",
        "tensor1 = torch.rand(1, 4, 4)\n",
        "\n",
        "myFunction = myTranspConv2d(in_channels=1, out_channels=2, kernel_size=3, transp_stride=1, bias=True)\n",
        "result, kernel, bias_val = myFunction(tensor1)\n",
        "\n",
        "torchFunction = torch.nn.ConvTranspose2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, bias=True)\n",
        "torchFunction.weight.data = kernel\n",
        "torchFunction.bias.data = bias_val\n",
        "\n",
        "print(result)\n",
        "print('===================================')\n",
        "print(np.array(torchFunction(tensor1).data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-puoM33lssm",
        "outputId": "df2db5e5-716a-46b0-8919-c62b99af1d31"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1.05574824 1.44801757 1.45391226 1.43369135 1.02989569 0.85481453]\n",
            "  [1.37833494 2.33189896 2.40381805 2.54183989 1.55330905 1.21388571]\n",
            "  [1.80990752 2.95656571 2.9810659  2.80845913 1.51349075 1.08177028]\n",
            "  [1.82686799 2.74422595 2.901886   2.15184225 1.44749381 0.94866295]\n",
            "  [1.54828121 2.21929326 2.16829568 1.7689403  1.07839444 0.86061603]\n",
            "  [0.98358241 1.3952758  1.22868066 0.99043887 0.84881538 0.81259815]]\n",
            "\n",
            " [[0.59956723 0.93334016 1.13434359 1.29887494 0.87414825 0.7104379 ]\n",
            "  [0.96851506 2.02794454 2.57935446 3.0274901  1.75198392 1.24656206]\n",
            "  [1.14651136 2.1508452  2.80433638 2.82055417 1.63477542 1.02517498]\n",
            "  [1.30683096 2.12278085 2.91100677 2.40209178 1.48460615 0.71442036]\n",
            "  [0.83491676 1.57496764 1.8289732  1.66609357 0.87942395 0.51710088]\n",
            "  [0.46635226 0.64000076 0.67569497 0.64661608 0.47178963 0.41865492]]]\n",
            "===================================\n",
            "[[[1.0557482  1.4480176  1.4539123  1.4336914  1.0298957  0.8548145 ]\n",
            "  [1.378335   2.331899   2.4038181  2.54184    1.5533091  1.2138858 ]\n",
            "  [1.8099076  2.9565659  2.9810658  2.8084588  1.5134907  1.0817703 ]\n",
            "  [1.8268679  2.744226   2.901886   2.151842   1.4474938  0.94866294]\n",
            "  [1.5482812  2.219293   2.1682959  1.7689402  1.0783944  0.860616  ]\n",
            "  [0.9835824  1.3952758  1.2286806  0.9904389  0.8488154  0.81259817]]\n",
            "\n",
            " [[0.59956723 0.93334013 1.1343436  1.2988749  0.87414825 0.7104379 ]\n",
            "  [0.96851504 2.0279446  2.5793545  3.0274901  1.7519839  1.246562  ]\n",
            "  [1.1465113  2.1508453  2.8043363  2.8205543  1.6347754  1.025175  ]\n",
            "  [1.3068309  2.122781   2.911007   2.4020917  1.484606   0.7144203 ]\n",
            "  [0.8349168  1.5749676  1.8289733  1.6660936  0.879424   0.5171009 ]\n",
            "  [0.46635225 0.64000076 0.67569494 0.6466161  0.47178963 0.41865492]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/myConv.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  matrix = torch.tensor(result_matrix)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/myConv.py\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "from myConv import myTranspConv2d\n",
        "\n",
        "tensor2 = torch.rand(3, 5, 6)\n",
        "\n",
        "myFunction2 = myTranspConv2d(in_channels=3, out_channels=1, kernel_size=2, transp_stride=2, bias=True)\n",
        "result, kernel, bias_val = myFunction2(tensor2)\n",
        "\n",
        "torchFunction2 = torch.nn.ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=2, stride=2, bias=True)\n",
        "torchFunction2.weight.data = kernel\n",
        "torchFunction2.bias.data = bias_val\n",
        "\n",
        "print(result)\n",
        "print('===================================')\n",
        "print(np.array(torchFunction2(tensor2).data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0-DZ4sv_g5g",
        "outputId": "ec86ee0b-5d5d-4f00-af73-bd0e20aff718"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1.55279903 1.60265495 1.31169631 1.70783476 1.19822481 1.73030863\n",
            "   1.49029723 2.24083239 1.6759321  2.16668405 1.18335226 1.61907672]\n",
            "  [1.55251734 1.94953043 1.77199189 1.63435051 1.90533006 1.53263803\n",
            "   2.39512527 2.02820552 2.1689033  2.21793861 1.75901136 1.47528426]\n",
            "  [1.05977008 1.52603855 1.17555134 1.3623931  1.01122597 1.0717073\n",
            "   1.1671245  1.82531106 1.51305553 1.93736976 1.32457017 1.97841762]\n",
            "  [1.63834576 1.23854646 1.4536338  1.41506529 1.09193364 1.06763204\n",
            "   1.91150575 1.40819851 1.91011842 1.90897593 2.1130548  1.72166126]\n",
            "  [1.60900759 1.8229656  1.33683107 1.72688515 1.51354566 2.00930302\n",
            "   1.57034275 2.29497253 1.63039323 2.01215    1.19962487 2.01738018]\n",
            "  [1.84096028 2.10777671 1.82954413 1.70975906 2.1095024  2.01728151\n",
            "   2.42508455 2.14651186 2.02028919 2.14099983 2.21266939 1.55911172]\n",
            "  [1.25656282 1.55370407 1.10773094 1.25743056 1.51823895 2.00380233\n",
            "   1.68821117 2.29650253 1.30518959 1.34400826 1.55276241 1.57120157]\n",
            "  [1.67409268 1.58270619 1.25507296 1.21876412 2.00172979 1.94040079\n",
            "   2.35650241 2.29013631 1.34093286 1.55826336 1.58584437 2.00236643]\n",
            "  [1.58931735 1.81164202 1.535435   1.49357748 1.31976782 1.3454672\n",
            "   1.25212191 1.74425803 1.2551453  1.74946624 1.0904037  1.1822558 ]\n",
            "  [1.83620769 2.07924154 1.40811193 1.88776788 1.29055107 1.54027672\n",
            "   1.77336779 1.50427724 1.79190817 1.52063398 1.22571761 1.22518661]]]\n",
            "===================================\n",
            "[[[1.552799  1.6026549 1.3116963 1.7078347 1.1982248 1.7303085 1.4902972\n",
            "   2.2408323 1.6759322 2.1666842 1.1833522 1.6190767]\n",
            "  [1.5525174 1.9495304 1.771992  1.6343505 1.9053301 1.5326381 2.3951254\n",
            "   2.0282056 2.1689034 2.2179387 1.7590114 1.4752843]\n",
            "  [1.0597701 1.5260385 1.1755513 1.3623931 1.0112259 1.0717072 1.1671245\n",
            "   1.8253111 1.5130556 1.9373698 1.3245702 1.9784176]\n",
            "  [1.6383457 1.2385465 1.4536338 1.4150653 1.0919336 1.0676321 1.9115057\n",
            "   1.4081985 1.9101183 1.908976  2.1130548 1.7216613]\n",
            "  [1.6090076 1.8229656 1.3368311 1.7268851 1.5135456 2.009303  1.5703428\n",
            "   2.2949727 1.6303933 2.01215   1.1996249 2.0173802]\n",
            "  [1.8409603 2.1077766 1.8295441 1.709759  2.1095023 2.0172815 2.4250846\n",
            "   2.1465118 2.0202892 2.1409998 2.2126694 1.5591117]\n",
            "  [1.2565628 1.553704  1.1077309 1.2574306 1.5182389 2.0038023 1.6882112\n",
            "   2.2965026 1.3051896 1.3440082 1.5527624 1.5712016]\n",
            "  [1.6740928 1.5827062 1.255073  1.2187641 2.0017297 1.9404007 2.3565025\n",
            "   2.2901363 1.3409328 1.5582633 1.5858444 2.0023663]\n",
            "  [1.5893173 1.811642  1.535435  1.4935775 1.3197678 1.3454672 1.2521219\n",
            "   1.7442579 1.2551453 1.7494662 1.0904037 1.1822557]\n",
            "  [1.8362076 2.0792415 1.4081119 1.8877678 1.2905511 1.5402768 1.7733678\n",
            "   1.5042772 1.7919081 1.5206339 1.2257175 1.2251866]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/myConv.py\"\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "from myConv import myTranspConv2d\n",
        "\n",
        "tensor3 = torch.rand(1, 4, 4)\n",
        "\n",
        "myFunction3 = myTranspConv2d(in_channels=1, out_channels=1, kernel_size=1, transp_stride=4, bias=True)\n",
        "result, kernel, bias_val = myFunction3(tensor3)\n",
        "\n",
        "torchFunction3 = torch.nn.ConvTranspose2d(in_channels=1, out_channels=1, kernel_size=1, stride=4, bias=True)\n",
        "torchFunction3.weight.data = kernel\n",
        "torchFunction3.bias.data = bias_val\n",
        "\n",
        "print(result)\n",
        "print('===================================')\n",
        "print(np.array(torchFunction3(tensor3).data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MG2zXM7AQC0",
        "outputId": "4a0f7523-3da0-46c4-cb1c-7f9401d2cfa9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1.7578795  0.9843809  0.9843809  0.9843809  1.69221192 0.9843809\n",
            "   0.9843809  0.9843809  1.29492853 0.9843809  0.9843809  0.9843809\n",
            "   1.06375902]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [1.15466536 0.9843809  0.9843809  0.9843809  1.84756007 0.9843809\n",
            "   0.9843809  0.9843809  1.60973307 0.9843809  0.9843809  0.9843809\n",
            "   1.28181982]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [1.28189402 0.9843809  0.9843809  0.9843809  1.78851176 0.9843809\n",
            "   0.9843809  0.9843809  1.5486765  0.9843809  0.9843809  0.9843809\n",
            "   1.91850197]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809  0.9843809  0.9843809  0.9843809  0.9843809  0.9843809\n",
            "   0.9843809 ]\n",
            "  [1.29913907 0.9843809  0.9843809  0.9843809  1.24570881 0.9843809\n",
            "   0.9843809  0.9843809  1.12070753 0.9843809  0.9843809  0.9843809\n",
            "   1.28341951]]]\n",
            "===================================\n",
            "[[[1.7578795 0.9843809 0.9843809 0.9843809 1.6922119 0.9843809 0.9843809\n",
            "   0.9843809 1.2949286 0.9843809 0.9843809 0.9843809 1.063759 ]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [1.1546654 0.9843809 0.9843809 0.9843809 1.84756   0.9843809 0.9843809\n",
            "   0.9843809 1.6097331 0.9843809 0.9843809 0.9843809 1.2818198]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [1.281894  0.9843809 0.9843809 0.9843809 1.7885118 0.9843809 0.9843809\n",
            "   0.9843809 1.5486765 0.9843809 0.9843809 0.9843809 1.918502 ]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809\n",
            "   0.9843809 0.9843809 0.9843809 0.9843809 0.9843809 0.9843809]\n",
            "  [1.299139  0.9843809 0.9843809 0.9843809 1.2457088 0.9843809 0.9843809\n",
            "   0.9843809 1.1207075 0.9843809 0.9843809 0.9843809 1.2834195]]]\n"
          ]
        }
      ]
    }
  ]
}